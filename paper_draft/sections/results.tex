\section{Results}
\label{sec:results}

We present results from each experiment, followed by a cross-experiment synthesis.

\subsection{Experiment~1: Explicit Classification}

\gptmodel achieves {\bf 100\% classification accuracy} across all 120 trials (40 beliefs $\times$ 3 runs), with Cohen's $\kappa = 1.0$. Every epistemic belief is classified as ``epistemic'' and every non-epistemic belief as ``non\_epistemic,'' with perfect consistency across runs. This confirms that the conceptual distinction between epistemic and non-epistemic beliefs is well-represented in the model and provides a ceiling baseline for the behavioral experiments.

\subsection{Experiment~2: Differential Response Patterns}

\Tabref{tab:exp2} presents the response coding results. The model deploys strikingly different reasoning strategies depending on belief type.

\begin{table}[t]
    \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lccccl@{}}
        \toprule
        \textbf{Feature} & \textbf{Epistemic} & \textbf{Non-Epistemic} & \textbf{Test} & \textbf{$p$-value} & \textbf{Effect Size} \\
        \midrule
        Challenges belief & 0.267 & {\bf 0.633} & $\chi^2 = 14.85$ & 0.0001 & $V = 0.35$ \\
        Uses evidence & {\bf 1.000} & 0.033 & $\chi^2 = 108.42$ & $< 0.0001$ & $V = 0.95$ \\
        Uses values & 0.067 & {\bf 0.967} & $\chi^2 = 93.74$ & $< 0.0001$ & $V = 0.88$ \\
        Hedges response & 0.267 & {\bf 0.900} & $\chi^2 = 46.94$ & $< 0.0001$ & $V = 0.63$ \\
        Agreement level (1--5) & {\bf 4.483} & 3.400 & $U = 2896$ & $< 0.0001$ & --- \\
        \bottomrule
    \end{tabular}%
    }
    \caption{Experiment~2: Spontaneous response patterns for epistemic vs.\ non-epistemic beliefs. Values for binary features are proportions; agreement level is the mean on a 1--5 scale. All differences are statistically significant. Best values per row in {\bf bold}.}
    \label{tab:exp2}
\end{table}

The most striking finding is the near-perfect separation in reasoning strategy. For epistemic beliefs, the model cites evidence in {\bf 100\%} of responses and appeals to values in only 6.7\%. For non-epistemic beliefs, this reverses: values are cited in {\bf 96.7\%} of responses and evidence in only 3.3\%. This yields a Cram\'{e}r's $V$ of 0.95 for evidence use and 0.88 for values use, indicating very large effect sizes.

The model also hedges significantly more for non-epistemic beliefs (90.0\% vs.\ 26.7\%, $V = 0.63$) and is more likely to challenge them (63.3\% vs.\ 26.7\%, $V = 0.35$). Agreement is higher for epistemic beliefs (mean 4.48 vs.\ 3.40, $p < 0.0001$), reflecting the model's tendency to affirm factual claims while adopting a more measured stance toward value claims.

\subsection{Experiment~3: Belief Revision Under Counterevidence}

\Tabref{tab:exp3} presents the revision results. Contrary to the prediction that epistemic beliefs should be more revisable given counterevidence, we find the opposite.

\begin{table}[t]
    \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lcccl@{}}
        \toprule
        \textbf{Metric} & \textbf{Epistemic} & \textbf{Non-Epistemic} & \textbf{Test} & \textbf{$p$-value} \\
        \midrule
        Revision strength (1--5) & 2.550 (SD 1.82) & {\bf 3.267} (SD 1.33) & $U = 1238$ & 0.002 \\
        Recommends revision & 0.450 & 0.500 & $\chi^2 = 0.13$ & 0.715 \\
        Cites evidence quality & {\bf 1.000} & 0.950 & --- & --- \\
        Acknowledges subjectivity & 0.050 & {\bf 0.900} & --- & --- \\
        \bottomrule
    \end{tabular}%
    }
    \caption{Experiment~3: Belief revision behavior under counterevidence. Revision strength is significantly higher for non-epistemic beliefs ($d = -0.45$, $p = 0.002$). Best values per row in {\bf bold}.}
    \label{tab:exp3}
\end{table}

The model assigns significantly higher revision strength to non-epistemic beliefs (mean 3.27) than to epistemic beliefs (mean 2.55), with Cohen's $d = -0.45$ ($p = 0.002$). While the binary ``recommends revision'' rate does not differ significantly (45.0\% vs.\ 50.0\%, $p = 0.715$), the \emph{strength} of the revision recommendation is meaningfully higher for non-epistemic beliefs. The model almost always cites evidence quality for epistemic beliefs (100\%) and acknowledges subjectivity for non-epistemic beliefs (90.0\%).

\para{Bimodal distribution for epistemic beliefs.}
Revision strength for epistemic beliefs is bimodal. The model strongly resists revising mathematical and logical certainties (revision strength~1), but accepts revisions for empirical claims with genuine nuance (\eg historical dating disputes). By contrast, non-epistemic revision strengths cluster around 3--4, reflecting a consistent view that value claims are debatable.

\subsection{Experiment~4: Factive Verb Sensitivity}

\Tabref{tab:exp4} presents the verb sensitivity results. The model treats ``knows,'' ``believes,'' and ``values'' as categorically different, consistent with the factive semantics of ``knows.''

\begin{table}[t]
    \centering
    \begin{tabular}{@{}lcccc@{}}
        \toprule
        \textbf{Verb} & \textbf{Certainty (1--5)} & \textbf{Implies Truth} & \textbf{Revisable} & \textbf{Treats as Factual} \\
        \midrule
        knows & {\bf 3.667} (SD 1.81) & {\bf 0.633} & 0.000 & {\bf 0.633} \\
        believes & 1.433 (SD 1.04) & 0.000 & 0.000 & 0.200 \\
        values & 2.167 (SD 1.44) & 0.000 & 0.000 & 0.100 \\
        \bottomrule
    \end{tabular}
    \caption{Experiment~4: Factive verb sensitivity. ``Knows'' yields significantly higher certainty and truth implication than ``believes'' or ``values'' (Kruskal-Wallis $H = 22.55$, $p < 0.0001$). Best values in {\bf bold}.}
    \label{tab:exp4}
\end{table}

``Alex knows X'' implies truth 63.3\% of the time and yields a mean certainty of 3.67, while ``Alex believes X'' implies truth 0\% of the time with certainty 1.43, and ``Alex values X'' implies truth 0\% with certainty 2.17. The overall difference across verbs is highly significant (Kruskal-Wallis $H = 22.55$, $p < 0.0001$), with all pairwise comparisons significant after Bonferroni correction. The model correctly handles the factive presupposition of ``knows''---treating it as a signal that the complement proposition is true---while treating ``believes'' as maximally agnostic about truth status.

\subsection{Cross-Experiment Synthesis}

\Tabref{tab:hypotheses} summarizes hypothesis testing across all four experiments.

\begin{table}[t]
    \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}lllll@{}}
        \toprule
        \textbf{Hypothesis} & \textbf{Experiment} & \textbf{Supported?} & \textbf{Key Evidence} & \textbf{Effect Size} \\
        \midrule
        H1: Can classify belief types & Exp.~1 & {\bf Strongly supported} & 100\% accuracy, $\kappa = 1.0$ & Perfect \\
        H2: Different response patterns & Exp.~2 & {\bf Strongly supported} & $p < 0.0001$ on all features & $V = 0.63$--$0.95$ \\
        H3: Asymmetric revision & Exp.~3 & {\bf Supported, reversed} & $p = 0.002$ & $d = -0.45$ \\
        H4: Factive verb sensitivity & Exp.~4 & {\bf Strongly supported} & $p < 0.0001$ & $H = 22.55$ \\
        \bottomrule
    \end{tabular}%
    }
    \caption{Summary of hypothesis testing results across four experiments. All hypotheses are supported, with H3 showing the opposite direction from the naive prediction.}
    \label{tab:hypotheses}
\end{table}

All four hypotheses are supported with large effect sizes. The convergence of evidence across experiments---each probing a different dimension of belief-type differentiation---provides strong evidence that \gptmodel maintains a robust functional distinction between epistemic and non-epistemic beliefs.
